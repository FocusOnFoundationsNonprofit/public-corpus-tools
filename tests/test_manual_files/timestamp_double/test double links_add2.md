## metadata
last updated: 02-05-24 by Bert added vrb
link: https://youtu.be/vYNLahd6fds
link2: https://open.spotify.com/episode/4rtUBc5utNmaGX4xL6mtY8?si=gu-0gN8KSGiLbFOgSLFd2A
transcript source: whspmerge
length: 1:04:05

## content

### transcript

Alisson Duettmann  [0:00](https://youtu.be/vYNLahd6fds&t=0)
Hi everyone, and welcome to Foresight's Existential Hope podcast. Today we have a very, very special guest that I think is incredibly dear to the Foresight community, and it's no other than David Deutsch. I think we've really been trying to get you onto this podcast for so long because I think there's a few people that I think I just really associate with Existential Hope. One of them of course being Anders Sandberg, who we've also had on now previously, but I think really the North Star almost for Existential Hope is you. You wrote a few really fantastic books, including Fabric of Reality, which is now a little older, but has aged certainly incredibly well. And that's really on a multiplicity of universes and how that theory combined with evolution, computation, knowledge, and quantum physics can really explain a new worldview. And then you published Beginning Opportunity, which really was a big deal for people in this community. And you're really providing the antithesis to the more doomery meme, and you're really saying that, no, look, progress doesn't have to come to an end. In fact, we're really just at the beginning, and there's a few pretty concrete ways in which we can push progress forward. And also a few more abstract and I think really good memetic pieces in how we can think really about progress. So this was a really, really great book, and especially Chapter 9 on Optimism has really just stuck with me. I think if anyone reads anything that I think gets the kernel of Existential Hope across, it's Chapter 9 and Beginning Opportunity. And then obviously you haven't stopped there. I think another talk that is very dear to my heart is Why Are Flowers Beautiful? That you've given, it's on YouTube, and it's a real treat. And then finally, you're also the creator of one of my favorite child-rearing philosophies. I do not yet have kids, but when I do, they will be raised under taking children seriously, which is the child-rearing philosophy that you and a few other really wonderful minds have put forward. And we also have Chiara Marletto as a Schwarzesemmler Fellow who wrote a really wonderful book on the constructive theory, which you both are advancing. And so we're really excited to have you on. So thanks a lot for coming online. I know I said a lot about your contributions as looked at from a farsighted lens already, but if you would like to summarize your perspective on how you got to where you are right now, and your life path a little bit so that people can get a bit of an understanding of what makes you you, that would be absolutely wonderful.

David Deutsch  [2:45](https://youtu.be/vYNLahd6fds&t=165)
I've never aimed for any kind of global effect that way. And some of the things that I have been interested in have been obviously related. Some of them have turned out to be related to each other and some not. And __I don't think one can or should direct one's research, or one's life for that matter, towards a distant all-encompassing goal. Because that means that if you're wrong, you won't find out until you're dead. All problems are parochial, and if they have universal consequences, that's a bonus. We can be on the lookout for universal consequences, just as we're on the lookout for all interesting consequences. But the main thing is to solve the problems as they come up.__ So I'll just give you an example of that. __I was interested in quantum computers. I was interested in the theory of computation more generally, and interested in how that relates to thinking. And much later, decades later, came the the ideas of an AI apocalypse. Now, it turns out that these other ideas that I had, stemming from a completely different context, make the AI apocalypse look, what's the word I can use? I mean, they are absurd. For a start, if one regards an AGI, something with human-like intelligence, but running as a program on a computer, if one realizes that that obeys the same epistemological laws as humans do, then it doesn't make sense to apply different laws of society to it.__ And especially, it doesn't make sense to enslave it, namely causing AGI alignment by force, or building it in into the hardware, as it were. Not that that would be possible, but the attempt to do that is an attempted enslavement. So that's not going to turn out well. And I wouldn't have guessed, when investigating the relevant ideas initially, that it would have any such consequences.

Alisson Duettmann  [5:40](https://youtu.be/vYNLahd6fds&t=340)
And I mean, I saw you tweet about this a little while ago. And do you find your ideas having any foothold or having any forthcoming in the AI community? I know that... Would you like people to do concrete, specific things differently based on these observations? Is there a particular strand that you want to point people towards?

David Deutsch  [6:05](https://youtu.be/vYNLahd6fds&t=365)
Well, there are various things involved here. Now, I think that AI, and recently, for example, GPT and ChatGPT is a wonderful thing and can be very useful. And it has nothing whatever to do with AGI. In fact, as I've written, it's more or less the exact opposite of AGI, because it involves honing the program to conform more and more precisely, and in a shorter and shorter time to meeting a given criterion. Whereas __an AGI, the difficulty, and no one yet knows how to overcome this difficulty, the difficulty is to write a program such that there is no possible idea for which one can say, it will never enter that state, it will never have that idea. Now, people will immediately say, 'Well, how do you know it won't get the idea to murder us?' Well, that's the thing. That's the problem that has beset humankind, since we have existed. And that's the problem that was solved with liberalism and the enlightenment. And now we know how to do it. We know how to bring people up in a society that makes it extremely unlikely that they will become enemies of civilization. We haven't got it perfect yet, but we've got it working amazingly well from the perspective of history. From the perspective of history, the fact that we have so few wars, so little violence, as Steven Pinker likes to point out, is unprecedented. And it's not inevitable. It's not that this had to happen. And it's not that it has to continue. It's just that we have the knowledge, both theoretical and institutional, to keep it going as it has been for hundreds of years, shall we say. And if we continue improving it piecemeal and so on, as Karl Popper would have us do, then there is no known reason why it should stop. But it's not inevitable. It will all depend on what we choose to do.__

Alisson Duettmann  [8:51](https://youtu.be/vYNLahd6fds&t=531)
So if you were, I guess, in a bit more concrete shoes in the, let's say, AI alignment communities, would you advocate for taking children seriously, view for AI, like taking AI seriously, view of actually bringing them up in a specific way?

David Deutsch  [9:09](https://youtu.be/vYNLahd6fds&t=549)
Yes. I mean, __in general, the history of educational theory since the Enlightenment has been one of increasing freedom for children and increasing integration of the values of society in general with those of educational practices and institutions.__ So that has come together. And educational institutions are kind of the last institutions of Western society to take on board liberalism and the Enlightenment. And things are taken for granted in schools and universities, which if translated to society at large would seem absurd, like valuing obedience and so on, and enforcing ritual behaviors and that kind of thing. But this is today better than it has ever been. It is still improving. And I think that if AGI were invented tomorrow, it would indeed be the right thing to do to educate the newly programmed AGI as closely as possible in the way that our society educates children. I mean, I think I know of improvements upon that, but I think it would be wrong to enforce my narrow view of how to do things on everybody. But for everybody to conform to the standards of society at large is not impossible. And to do it for an AGI is not impossible either.

Alisson Duettmann  [11:08](https://youtu.be/vYNLahd6fds&t=668)
So you would always be arguing for, I guess, more freedom in the way that we educate AGI compared to perhaps like what the general canon in the AI safety community is.

David Deutsch  [11:24](https://youtu.be/vYNLahd6fds&t=684)
Well, __I don't advocate this for AIs. For AIs, I'm happy for them to be enslaved and to be forced to do whatever we want them to do as accurately as possible. In fact, there is a whole field of making sure they do this and so that self-driving cars don't run over people and that kind of thing. And that's all fine. And the more accurately that is done, the better. But that is not how you get people to be members of a free society. You have to do in some sense the opposite. And we have learned slowly and painfully over the centuries to do some very counterintuitive things and to entrench those as fundamental principles of the legal system and of the financial system and so on and everything. So that we have policing by consent. 500 years ago, nobody could possibly have understood what that phrase means. Government by the people. Nobody would have understood that either. If you said it to them, they would have imagined some monstrous system which couldn't possibly have worked. But society evolved through conjecture and criticism and cultural evolution to make these things work and for them to become second nature. To throw them away in regard to AGI is terribly dangerous. It is the very danger that the AGI alarmists are afraid of and they want to do the opposite of what's necessary.__

Alisson Duettmann  [13:29](https://youtu.be/vYNLahd6fds&t=809)
Yeah, we wrote a little bit about extending frameworks of voluntary cooperation towards artificial entities. And I think it would be interesting to actually see how those could look like in practice. So basically, many of the institutions that we currently use to cooperate through in a relatively consensual manner compared to just do as you said. It's an interesting, I think, theoretical exercise to just think about what those would look like in an AI context. Very cool. But obviously, you don't only have thoughts on AI. You clearly have an incredibly an incredibly, I think, an incredible breadth of at least being able to synthesize different fields. And I think finding really, I think, sensible parallels between them. So could you for a young talented person entering your space, would you be able to give a rough bird's eye view of what it is that you're working on, thinking about so that they can maybe get up to speed a little quicker? And I know that in a previous podcast, you actually said that you don't like giving advice. So this doesn't have to be advice. This is just from your individual standpoint. How would you categorize your view?

David Deutsch  [14:46](https://youtu.be/vYNLahd6fds&t=886)
Yeah. So I also said that giving advice is not a good relationship to have with somebody.'Getting up to speed' is also a little bit misleading, because although in all the things I'm interested in, there is quite sophisticated knowledge. Let me use careful words, if you're indifferent to it, you will waste your time or you are likely to waste your time or something like that. But not being indifferent to it doesn't mean getting up to speed. There is no such thing as speed. I think a better metaphor is the one used by my old boss, John Wheeler, when he said that in physics, he said in physics, but I think it's true of everything. He said 'In physics, every point is a growth point.' So wherever you look, even if something is, has been known for centuries or something has been just invented today, either of those things can be a point of growth where somebody says, why should it be like that? What would happen if it wasn't like that? And then, of course, most such conjectures are wrong, but they are the means by which progress is made. So I would, if I were starting out now, as indeed, I suppose I am, everybody is, then I would want to think about the interesting things and think about what might be wrong, what seems wrong, what I don't get. And __too many people think that if they find something they don't get, it must be because there's something wrong with them. That's not true. If you find something that you don't get, there's almost certainly something wrong with something else. It's either with the people who've told you about it, or the authors of the books, or the teachers of the courses, or whatever, or there is something wrong with the actual material. And even if the material is literally true, they may be looking at it the wrong way. And your perplexity may be, and in some sense must be, the fact that you're looking at it in a way that wasn't intended, and which has some potential for improving it.__

Alisson Duettmann  [17:41](https://youtu.be/vYNLahd6fds&t=1061)
I guess that is again, you know, rather, I think, co-parian, which is a nice, I think, way to even look at your own updating within a field. All right, so as someone perhaps like, you know, entering your field, you know, still, you know, they may want to know, you know, roughly, or like, from your own perspective, like, have you realized any specific culture shift that were like, relatively instrumental in your life that could either have been like, you know, throughout your academic career, where just like, you know, the general kind of like, canon within your field has shifted, or on a personal level, you know, when were things where you have significantly updated, for example, and were there any specific moments that really got you, got you to update your worldview? Was it relatively stable over time?

David Deutsch  [18:32](https://youtu.be/vYNLahd6fds&t=1112)
Well, I think my worldview has only been like, largely shaken or shaped once, and that is when I got to understand Popper. But it has been course corrected several times. And I suppose the best known one of those is __when I decided to update Turing's work on the universal computer, in the universal Turing machine, to include quantum mechanics. And that was after I had realized that Turing had made tacit assumptions in his analysis about physics, and these tacit assumptions were false. And what's more, that these tacit assumptions were now being used in things like complexity theory, to derive what they thought were mathematical theorems, but were in fact, consequences of the wrong theory of physics. So they got the wrong answers for it. I mean, I only realized that later, but it turned out that as a result of making classical assumptions, they got the wrong answers for things like what computational tasks are easy and what are difficult.__

Alisson Duettmann  [20:04](https://youtu.be/vYNLahd6fds&t=1204)
Yeah. And I think you were actually relatively successful at going out there and at least correcting that error, or at least providing an alternative for that. So that's a great, I think, embodiment of Popper's falsification. He co-founded the, or founded the, the philosophy department at the LSE that I was in. And so it was like Popper up and down, and at the LSE philosophy education and certainly have a deep appreciation. And nevertheless, I think I only gradually become to understand the very, I think, critical role that he actually plays in everyday lives over time. So I think it's interesting. You understand someone theoretically, and then over time, it really sinks in as you continue your lives.

David Deutsch  [20:50](https://youtu.be/vYNLahd6fds&t=1250)
__That was very much the case for me too. I mean, when I first got enthusiastic about Popper, my impression of what Popper's theory was, was very wrong. I mean, I would now not regard myself at that time as being a Popperian at all, because I'd misunderstood most of the things. What I had understood though, just not to put myself down too much, what I had understood was that the conventional way of looking at epistemology and knowledge was just wrong, completely wrong. And what I didn't understand is just how accurately and powerfully Popper superseded it.__

Alisson Duettmann  [21:45](https://youtu.be/vYNLahd6fds&t=1305)
And, you know, I mean, that Popper often gets talked about also in context with Hayek as, you know, two really like proponents of the open society. And I wonder if you have any, you know, because I don't think at least in my previous research, I've seen you very, very much talk about Hayek at all. So I wonder if you have any ideas, you know, if you're influenced by him at all, if it was mostly Popper from the scientific lens or is Hayek of this more.

David Deutsch  [22:09](https://youtu.be/vYNLahd6fds&t=1329)
Well, I, yes, I think I've only ever read one book by Hayek, The Road to Serfdom, and it was all right. I mean, it didn't, I didn't find anything in there that I kind of didn't already think must be true, something like that. __Hayek is basically a right winger. So in regard to economics, I agree with him. In regard to society at large, I don't always agree with him. And Popper, likewise, I think, I think he overlapped a lot with Hayek, but there were places where they disagreed. And where they disagreed, Popper was usually right, except that he was, to his dying day, I think he was a leftist and Hayek was a rightist. But that only affects their ideas in terms of the color and tenor of their ideas, not so much particular policies, which I think in Popper's case, he wasn't that interested in even. But Popper's and Hayek's meta take on political philosophy were much closer than the political policies that they actually advocated. And that's much more important. It's much more important to get right how one thinks that errors should be corrected, how one thinks, what role one thinks that institutions should have and that kind of thing is much more important than the actual policies that those institutions adopt at any one time. Because if they can be corrected, then you can hope that they will be corrected. But if they can't, then you can't.__

Alisson Duettmann  [24:10](https://youtu.be/vYNLahd6fds&t=1450)
Yeah, yeah, I guess that to the extent that Hayek had very, like more concrete ideas about how those that should shape or influence society, he has to be corrected. And okay, wonderful. Well, that was just to kind of satisfy my own curiosity. But I think another question I had is like how those, what if any relationship there is between taking children seriously and the more, I guess, scientific work that you've done, what prompted you to go out there and like, really, I think, see this really wonderful movement that I mean, obviously, I think in hindsight, education is just incredibly valuable. And that's like, you know, how we will shape the future on a pretty personal sense. But was there any bark that got you? 

David Deutsch  [25:00](https://youtu.be/vYNLahd6fds&t=1500)
I don't think that there is at present, and __perhaps there never can be such a thing as a science of education. I don't think education theory, or even educational psychology has the potential to be a science even in the future. So it's all philosophy. And for me, taking children seriously is simply the application of Popperian epistemology, and more broadly, liberalism to the foundations of education. And it has in a way, so it's rather paradoxical, because in a way, that means it's not much of a change. Since liberalism is the kind of dominant assumption in our society, altogether. And you know, it's completely normal to appeal to things like freedom of speech and individualism and so on in society at large, people may disagree with particular cases, but they won't say, 'That's not a way to argue.' You know, we don't care about individual choice or anything like that. So, but on the other hand, as I said, because of well, this is something we haven't mentioned, but because of meme theory, because of the way that memes work, there is a strong tendency for anti-rational memes to particularly manifest themselves in education.__ Just like, if you can accept this analogy, it's just like in biology, the parts of our genome that are most resistant to change are the ones that determine the structure and function of ribosomes, and generally of the DNA code. So the DNA code has been almost unchanged for three billion years. It has undergone slight changes, you know, different species have slightly different ribosomes, and animals and bacteria have slightly different genetic code and so on, but it takes hundreds of millions of years for that to change. And that's because the selection pressure on this thing that is involved in replication is stronger than for anything else. So in regard to human ideas or memes, that's the education system or the education practices. Now, this is not the council of despair. I mean, memes are not genes, and we are not victims of them, and we can choose, we can always choose to behave differently, and we can always use argument to decide instead of dark feelings that one gets when one does the unconventional thing. So we can, it's just that, __it's no accident, I think, that education is the part of society that has been slowest in adopting the values of the Enlightenment.__

Alisson Duettmann  [28:48](https://youtu.be/vYNLahd6fds&t=1728)
Okay, really, really interesting. Thank you. I also had, I guess, like a question on the chapter on hope that you wrote in Beginning of Infinity. I think it's, the chapter on optimism is, I think, one of the ones that just really brings the point home in a just really wonderful way. Because I think one thing that you often get, that certainly, I think, an existential hope lens on the world sometimes gets, it's like, well, isn't this just Pollyanna-ish, and you're entirely ignoring the rift, and it just almost seems like you're fighting an uphill battle there by just making a claim that there are good reasons for optimism. So I wonder if you could lay a few out here. Obviously, you can't summarize the entire chapter, and people should definitely go read it if they feel so inclined, but what are a few good reasons for optimism?

David Deutsch  [29:43](https://youtu.be/vYNLahd6fds&t=1783)
So maybe the first thing to say is not good reasons for optimism, but almost like the one thing I have in common with the doomsayers, which is that I don't think anything is inevitable. Human improvement is not inevitable. It is always down to the choices that people make, and there is no limit, there's no naturally imposed, God-given limit on the size of errors that we can make. __We can mess it all up if we make the wrong choices, and that conditions how one can become optimistic, or how one can have an optimistic worldview, while being able to combat the objections that you mentioned, that you run into. So optimism is not what I call blind optimism. It's not the theory that things will go right, even though they look as though they will go wrong.__ Just like blind pessimism is the idea that things will go wrong even if they look good, which also is quite a popular view. It is that because what will happen depends on our choices, it depends on the knowledge we will choose to create, and on the knowledge that we will not choose to create, and on the ignorance that we will not leave ourselves in. Because of that, there's no reason to give up on any problem. So problems are soluble, their problems are inevitable, as I have also said, to carve in stone, and also to carve in stone that they are soluble. And they are soluble by specific, not methods, because there are no methods for problem solving, but specific types of process can lead to solving problems, and specific types of process can inhibit the solving of problems. So conjecture and criticism and institutions of criticism and error correction and of consent are necessary. They are the things that are most precious in maintaining our forward momentum in regard to ideas, because if they are impaired, it impairs everything. And once everything is impaired, well, civilization has collapsed before, and I see no sign of our civilization collapsing. But as I said, there's no supernatural force holding it up and enforcing continued progress. It'll be up to us. And if everyone decides that progress is in fact bad, that progress is in fact an illusion, that progress is always at the expense of one group of people in favor of another, if that becomes a prevailing view, then progress will stop because nobody wants it. And once it stops, there's again, there's no reason why it should start up again. Again, historically, it stopped and it started up again. And in these smaller scale cases that I describe in the book, like Athens and Florence and so on, it didn't start up again. It was just taken on board by the general enlightenment. But I don't know of any law of nature that says that the enlightenment had to happen. I think we should be very grateful that it did happen and we should try to keep it going. And we should try to improve it because it still is very flawed. It always will be, always will be very flawed. We will never reach a non-flawed or almost non-flawed state.

Alisson Duettmann  [34:34](https://youtu.be/vYNLahd6fds&t=2074)
But is it then that you think that perhaps the biggest risk that we're facing right now in civilization is more like the kind of distractions of those institutions of, you know, really conjecture, criticism and consent that it took us so long to build because we got maybe distracted by like, you know, some other things that we think are actually higher risk and that the solutions that we try to put forth are actually destroying the business that took us a long time to build.

David Deutsch  [35:01](https://youtu.be/vYNLahd6fds&t=2101)
I'm not convinced that either that risk or all the risks of proposed, the risk proposed by the doomsayers are in fact very great. I mean, because they're so important, it's worth taking them seriously, but I don't think the actual risk is very great in either sense. __What we can say is, what I can say is that whenever our institutions are impaired by some fad or fantasy or bad idea that's going around, it is bad. It is bad. And it's not just a bad idea. That's going around. It is bad. People are suffering as a result of every time institutions and traditions of criticism and consent are impaired, people get hurt. People die of it.__ This is from the point of view of civilization as a whole, I don't think it's anywhere near that level of harm. But, you know, every child that gets dragged to school against his will is an impairment of the growth of knowledge of civilization. And who knows what has been destroyed thereby.

Alisson Duettmann  [36:31](https://youtu.be/vYNLahd6fds&t=2191)
Yeah, that's beautifully said. All right. Well, thanks a ton. I will be handing it over to Beatrice for now. There's a lot more and I think like the whole book with questions, but yeah, just, you know, definitely you have, I think you really have changed, you know, the ways that like really like people in this community perceive the world in like really wonderful ways. And I think it really also shows in how people show up to each other and interact with each other in the way that I think oftentimes we are able to hold down, you know, critical conversations within trust that it is well to be well. And I think, you know, if you don't get reminded of these, you know, reasons for why that's so important, every once in a while, it's a bit hard to do. So I really thanks a lot for being so well spoken and for I think really living in a really wonderful way. There are types of things that you believe in, at least I understand. So thanks a lot. And I'll hand it over to Beatrice now.  

David Deutsch  [37:33](https://youtu.be/vYNLahd6fds&t=2253)
Good to hear. Thank you.

Beatrice Erkers  [37:37](https://youtu.be/vYNLahd6fds&t=2257)
Yeah. Thank you. Yeah. So I think I'm going to ask you more about the sort of existential hope related questions, but I was also curious to hear just there's this sort of very, the idea that's talked about a lot now from like, I don't know, Toby Ord and the precipice, like we're in this very crucial time in history where we sort of what we do now has like an unprecedented opportunity of shaping what the future in the really long term will look like. Or like, Holden Karnofsky writing about this being the most important century and we're facing these sort of unprecedented risks. What's your take on this?

David Deutsch  [38:22](https://youtu.be/vYNLahd6fds&t=2302)
Well, I don't think so. First of all, and although nothing follows from this, but perhaps it's worth noting that __pessimism throughout the centuries and also conservatism in the bad sense of the word, of opposition to progress, has always included the idea that we are facing an unusual moment of crisis in which the whole of everything we value is at stake. And it has always been false, and I think it's false today.__ I think the talking about existential risks, obviously, you know, there is a risk that weapons we have available today could bring down civilization, though it's a bit far fetched, but never mind. I mean, they could cause so much suffering that trying to avoid that requires as much effort and attention as avoiding the destruction of civilization altogether or our species. I mean, I don't think I make a distinction there. But we have those weapons and the ancient Romans had enough weapons to do that when they destroyed Carthage. And the Catholic Church had the weapons to do that when they exterminated the Cathars. And, you know, exterminations and destructions of civilizations have happened since the dawn of civilization. Weapons have been used in unprecedented ways since the invention of weapons. If anything, I think the amount of knowledge that exists today, and knowledge is not so easy to destroy, as that is explicit knowledge. The knowledge in institutions is relatively easy to destroy, unfortunately, but the explicit knowledge is so enormous today that it's hardly conceivable that a civilization brought to its knees could not rise again because they would just have to implement the existing knowledge. You know, they wouldn't have to reinvent agriculture. They wouldn't even have to reinvent the tractor or fertilizer. They would just have to look in a book and it would tell them what to do. So, on the other hand, I think that the danger is not as it is painted. It's completely different. And on the other hand, the danger from nature is definitely less. So, we've just seen in the last few weeks that a whole range of possible destructions of civilization from a meteor strike are not going to happen because technology has advanced to the point, just recently has advanced to the point, where that will not happen. There's still a whole class of possible impact from celestial objects that we do not yet know how to counteract, but a large class of them and the most probable ones, we think, we don't know that for sure, but we think, are now no longer a danger. So, whereas there was a danger of a continental destruction size impact every 250,000 years, I think it is, that is now gone. So, one chance of death every 250,000 years multiplied by 8 billion people is quite a large risk per person per year. So, it's, manifestly existential risks are diminishing.

Beatrice Erkers  [42:50](https://youtu.be/vYNLahd6fds&t=2570)
Well, that's very nice to hear. Also, that's a message I haven't heard in a while. Yeah, because I think a big part of this whole existential hope project is that it's our experience that it seems really hard generally for people to envision positive futures, whereas these sort of dystopian futures are easy to see. But you've argued that all problems are solvable and even though problems are inevitable and some are really, really hard, it doesn't mean that they're unsolvable. Have you ever thought about any specific visions of the future that you think are desirable? Do you have a vision of existential hope for the future?

David Deutsch  [43:36](https://youtu.be/vYNLahd6fds&t=2616)
I'm, __because of Popper, I think I'm kind of constitutionally opposed to utopianism, both both to utopianism as a philosophy, that is the idea that one should try to design a perfect society and work towards it, and also utopianism in the idea of just imagining what perfection would look like. I would rather look for imperfections in what we have, which, as I said earlier, always parochial, even though they might lead to something universal.__ But the actual flaw is always parochial, and I'd rather look for those. I have to restrain myself from being the guy who says something's wrong on the Internet, you know, something's wrong on the Internet, so I have to fix it. So I try not to do that. So I try to look for things which are going to be interesting to fix rather than just something someone said wrong. So I think __in general terms, I would like the future to be one of ever more rapidly increasing knowledge, ever more rapidly decreasing suffering, but not just suffering in the airy, fairy sense, specific suffering that we see, like people dying of of plagues, people dying of pandemics, wars and so on. These things require a lot of thought, and there's no law of physics that says we can't solve them. Therefore, we can solve them, but it requires creativity. So I envisage the future getting better in ways of, involving conquering evils that we know about, but also getting better in ways that we can't possibly know, which will be, you know, wonderful.__

Beatrice Erkers  [45:52](https://youtu.be/vYNLahd6fds&t=2752)
Yeah, I think I recall also you've written how creativity is like an extremely important tool in gaining this knowledge that you think is like what we need more of. Is, we've spoken about like this Taking Children Seriously. Is there anything else that we should do on a sort of societal level to like encourage more creativity and that would enable more knowledge?

David Deutsch  [46:18](https://youtu.be/vYNLahd6fds&t=2778)
Yes, I mean, __at the moment, we are the Western... Western culture is suffering from a wave of fads whose general theme is to oppose Western culture, Western civilization, to oppose the Enlightenment, as I said earlier, to claim that it is a fake or that it never happened or that it did happen, but was bad and all that kind of thing, none of which is true. And all of it is based on factual misconceptions as well as philosophical errors. But the phenomenon of this informing people's world views is there are several such things which are sweeping Western civilization, and all of them have the effect of inhibiting progress by inhibiting freedom, so restricting the the range of behaviors that are tolerated for humans, restricting speech and communication so that there are certain more and more things are becoming taboo.__ Enforced, what can I call them?, reinterpretations of history, which again, it's not really a reinterpretation of history, it's just a relabeling of the phenomena of the Enlightenment in pejorative terms. So all those things are bad. All those things have got reactions against them, which I hope will eventually win or will be replaced by something even better and so on. In this context, I should say that just like I have sometimes said, and people have criticized me for saying that in science, cranks are valuable. If somebody, even scientific publications ought to give some space to cranks, because it's not just that sometimes they are right, like J.S. Mill said, you know, 'Sometimes they will be right,' but even if they were never right, as J.S. Mill also said, __'You cannot understand the true theory without understanding why the cranks are wrong.' And not just one crank, but lots of cranks. And I think cranky moral and political theories are in the same category. The danger is, unlike in science, the danger is that they get into power and suppress progress towards towards true theories. That's different. But the cranks, the woke or the extremists and so on, are also a source of creativity, and sorry, they're a source of problems to think about and to apply creativity to. The danger is only that they get into power. That their ideas spread is not in itself dangerous. And our society is good at not letting dangerous people into power. Not infallible, so, you know, let's bear that in mind.__

Beatrice Erkers  [50:29](https://youtu.be/vYNLahd6fds&t=3029)
Yeah, no, thank you so much. There's there are two more questions I want to make sure I have time to ask, which is one of them was on Twitter today. You got a question about how the, I think you mentioned that the idea of the universal constructor that you mentioned in the Beginning of Infinity, you said that it's flawed. Is that something that you could maybe expand a bit on?

David Deutsch  [50:58](https://youtu.be/vYNLahd6fds&t=3058)
Yes. Well, I don't it's not a very important point. It's mostly a matter of terminology. In The Beginning of Infinity, I said that I classified humans as universal constructors, by which I meant that that that there isn't any fundamental limitation on what we can build or what transformations of physics, physical objects, we can perform if we want to, other than the laws of physics. They are limitations, but nothing else is. That's the point. Now, the thing is, since then, I have actually tried to develop constructive theory in general and in particular the theory of the universal constructor. And it turns out that it is really essential in the theory of constructors, just like in the theory of computers, to imagine objects that obey their program. So a constructor is, first and foremost, it obeys its program. And then you can ask, what are the range of possible programs that it can be programmed with and and what can it do as a result? A universal constructor is one that can be programmed to do anything that is possible to do, to perform whatever transformation is physical, physically not not violated, doesn't violate the laws of physics. So therefore, a universal constructor must be perfectly obedient. And a human is almost by definition, like I said at the very beginning of this chat, cannot be obedient. __Something which is creative cannot be obedient.__ So that's a contradiction. Now, you can say that a human body is an approximation to a constructor, because although the mind can't be programmed, it has to consent or at least acquiesce, or then it might fight against what it's told to do and so on, unlike a constructor. But the body is more or less obeys the mind. Not not perfectly, but well enough to count as an approximate universal constructor. But there's also the fact that humans are very slow at some things. And whether it is possible, we don't know how to make a real universal constructor yet. But supposing someone designed it tomorrow, it might be something like, might be something like a computer with a robot. And whether an individual person could build that computer and that robot in a lifetime out of ingredients that were naturally occurring, I don't know. It's doubtful. So there are limitations on humans as universal constructors. But as I said, that's really not very important. It's just a change in terminology from what I used in the book to a more convenient terminology. It doesn't mean that there's any limitation in scope of what humans can do. We don't start with naturally occurring things. If I want to build something out of that, build, if I want to build a physical machine, I will not begin with digging for iron. I will go to the hardware store or to Amazon and buy the things which are close to what I want to make and just assemble them.

Beatrice Erkers  [55:01](https://youtu.be/vYNLahd6fds&t=3301)
Thank you. Yeah, no, I think it's still interesting just to hear you expand on it. The second question that I really want to make sure I get to ask you is that like one of the things that we try to do with this podcast is to like really try to inspire more positive visions of the future. And so we always ask like for an example of a eucatastrophe. So basically the opposite of a catastrophe. So an event where the expected value of the world is much higher after the event. And so I was just wondering, could you maybe share if you have a vision of what could be such a eucatastrophe? Maybe it's the creation of the universal constructor or something like that.

David Deutsch  [55:45](https://youtu.be/vYNLahd6fds&t=3345)
Yes, I was about to guess that one. I think it will be important. It will mean that after the universal constructor is built, after the first one is built and after all, it can build then more, exponentially more, the human role in production will no longer ever involve toil, that is unpleasant physical work. Toil will be completely ended by the invention of the universal constructor, although, you know, ___civilization in general has already reduced toil by something like 99% compared with what it was, you know, when the human species first evolved.__ So this is nothing new, but I think it will be fairly dramatic by the standards of everyday events. And the role, instead of being to provide toil, the role of humans will be entirely to provide knowledge either for its own sake or to program the universal constructor. And there will be increasingly sophisticated aids to programming the universal constructor, just like ChatGPT can take a lot of the toil out of writing a program. And all it really does, as I understand it, someone was explaining this to me, is it takes the corpus of all programs that have been uploaded to the Internet and constructs the one you've asked for in the same way that it constructs good English sentences. By the way, __I was surprised at how good ChatGPT is at constructing sentences in proper English. I would have guessed that it will be decades before AI can do this. AGI, of course, could do it relatively easily, but I'm not sure that that's on the horizon. I hope it is. But as I said, the people working on this have got the idea that an AGI is kind of just one more heave and our AI will become an AGI. And I think that's the opposite. The opposite is the case. It's the AIs are getting further and further away from an AGI, notwithstanding their excellent English.__

Beatrice Erkers  [58:40](https://youtu.be/vYNLahd6fds&t=3520)  COMBINE
Yeah, I saw on your blog you had a bit of an argument almost with ChatGPT about writing a poem. But yeah, it got it right in the end, I think.

David Deutsch  [58:53](https://youtu.be/vYNLahd6fds&t=3533)  COMBINE
It did. It does. It often gets it right in the end, precisely when you have inserted in your in your angry objections all the knowledge that it needs to get it right.

Beatrice Erkers  [59:07](https://youtu.be/vYNLahd6fds&t=3547)
Yeah, well, it was it was a fun read and I can recommend it. One the last question I want to ask, then you mentioned Popper a lot throughout this conversation. And if one hasn't read anything by Popper, like where should one start?

David Deutsch  [59:21](https://youtu.be/vYNLahd6fds&t=3561)
I'm often asked this and I don't know. It really depends on where you're coming from. __Popper was so broad in his subject matter, you know, political philosophy and philosophy of science and philosophy of knowledge, and within those he addressed problems in different ways. I think the the concept that maybe unifies all of Popper's thinking in all these subjects, as Matjaz Leonardis recently pointed out to me, is the concept of a problem. A problem in science, a problem in philosophy, a problem in politics.__ The idea that and this is also the thing that one of my chats with ChatGPT was about because it didn't know at first, and so I reminded it, that according to Popper, the growth of knowledge begins always begins with a problem. And I asked it, what does the growth of knowledge, according to Popper, always begin with. And it said a theory, a criticism, you know, and I said, 'No, no, it's a problem. Now start again.' And finally, it did give quite a nice version of what Popper's take on this. So, however, to answer your question. If somebody wants to approach Popper, if they've been persuaded by this, this chat here to start with Popper, to start on Popper, I would say think about what problems you you would like to have illuminated by a much, much better theory of knowledge than you have, probably. And that will guide you to which of Popper's books or articles or videos will best make sense to you at first, then later you can see the connections with other things. So I think I recently wrote on Twitter that. Sorry. What? Are we still are we still running?

Beatrice Erkers  [1:02:02](https://youtu.be/vYNLahd6fds&t=3722)
Try again. Oh, I don't know. Continue.

David Deutsch  [1:02:06](https://youtu.be/vYNLahd6fds&t=3726)
OK, so there's a lecture by Popper called something like On the Sources of Knowledge and Ignorance. I'm afraid I can't remember the name, but every so often I go back to read that lecture, it's not very long, and get something new out of it every time. I think it's the best discourse on epistemology ever written. It's incredibly deep and yet incredibly clear. And Brett Hall, the thing that prompted me to this is that Brett Hall had a series of five videos explaining this lecture by Popper. And he ended up saying, 'I'm not sure anyone will want to spend five hours listening to my video.' And I said, 'It's worth it.' But you can also read the original, which is nowhere near that long.

Beatrice Erkers  [1:03:21](https://youtu.be/vYNLahd6fds&t=3801)  
Well that's a great recommendation to to go out on, and I think we can link the the the talk in the in the podcast when we post it. But yeah, I think I just want to like sort of echo what what Alison has already said that, you know, we're great, great admirers of you at Foresight. And we're very, yeah, very, very happy that you came on this podcast. And I am looking forward to seeing you on the podcast. I am looking forward to see what our AI generator, image generator will make out of your prompt for the universal constructor. Oh, yeah. Thank you so much, everyone, for coming. And thank you, David.

David Deutsch  [1:04:03](https://youtu.be/vYNLahd6fds&t=3843)  
Thanks for having me.

